<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>quantized speechT5 tts</title>
    <script type="module">
        import { AutoTokenizer, AutoProcessor, SpeechT5ForTextToSpeech, SpeechT5HifiGan, Tensor } from 'https://cdn.jsdelivr.net/npm/@xenova/transformers';

        // Define the generateSpeech function
        async function generateSpeech() {
            const text = document.getElementById('textInput').value;

           // Load the tokenizer and processor
const tokenizer = await AutoTokenizer.from_pretrained('Xenova/speecht5_tts');
const processor = await AutoProcessor.from_pretrained('Xenova/speecht5_tts');

            // Load the models
            const model = await SpeechT5ForTextToSpeech.from_pretrained('Xenova/speecht5_tts', { quantized: false });
const vocoder = await SpeechT5HifiGan.from_pretrained('Xenova/speecht5_hifigan', { quantized: true });


           // Load speaker embeddings from URL
const speaker_embeddings_data = new Float32Array(
    await (await fetch('./new_embeddings.bin')).arrayBuffer()
);
const speaker_embeddings = new Tensor(
    'float32',
    speaker_embeddings_data,
    [1, speaker_embeddings_data.length]
)
            // Run tokenization
const { input_ids } = tokenizer(text);

            // Generate waveform
            const { waveform } = await model.generate_speech(input_ids, speaker_embeddings, { vocoder });
console.log(waveform)

            // Create a Blob from the result and play it
            console.log(waveform);

             // Create an AudioContext
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();

            // Create an AudioBuffer to store the audio data
            const buffer = audioContext.createBuffer(1, result.audio.length, result.sampling_rate);
            const channelData = buffer.getChannelData(0);

            // Copy the audio data from Float32Array to the AudioBuffer
            channelData.set(result.audio);

            // Create a buffer source and play the buffer
            const source = audioContext.createBufferSource();
            source.buffer = buffer;
            source.connect(audioContext.destination);
            source.start();
        }




        // Expose the function to the global scope
        window.generateSpeech = generateSpeech;
    </script>
</head>
<body>
    <h1>Akari AI voice TTS. (quantized version)</h1>
    <textarea style="width:100vw;" id="textInput" rows="4" cols="50" placeholder="Enter text here"></textarea>
    <br>
    <button style="width:100vw; height:5vh;" onclick="generateSpeech()">Speak ðŸ—£ðŸ—£ðŸ”¥</button>
</body>
</html>
